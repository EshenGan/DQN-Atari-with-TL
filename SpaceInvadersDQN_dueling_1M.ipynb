{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SpaceInvadersDQN_dueling_1M.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "background_execution": "on"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yZ8GQn4DwRHI"
      },
      "outputs": [],
      "source": [
        "!pip install gym[atari]\n",
        "!pip install stable-baselines3[extra]\n",
        "!pip install keras-rl2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gupload"
      ],
      "metadata": {
        "id": "TsSVF3eNwKj_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# IMPORTS"
      ],
      "metadata": {
        "id": "pk-cF2v40lcu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pydrive.auth import GoogleAuth\n",
        "from google.colab import auth\n",
        "import tensorflow as tf\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import gym\n",
        "import tensorflow as tf\n",
        "from rl.agents.dqn import DQNAgent\n",
        "from rl.policy import LinearAnnealedPolicy, BoltzmannQPolicy, EpsGreedyQPolicy\n",
        "from rl.memory import SequentialMemory\n",
        "from rl.core import Processor\n",
        "from rl.callbacks import FileLogger, ModelIntervalCheckpoint\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()"
      ],
      "metadata": {
        "id": "gccsnf39wIXG"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GAME ENV PREPROCESS"
      ],
      "metadata": {
        "id": "Kp1R5nYf0oVi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputShape = (84, 84)\n",
        "windowLength = 4\n",
        "\n",
        "class AtariProcessor(Processor):\n",
        "    def process_observation(self, obs):\n",
        "        assert obs.ndim == 3 \n",
        "        imgs = Image.fromarray(obs)\n",
        "        imgs = imgs.resize(inputShape).convert('L')  \n",
        "        obs = np.array(imgs)\n",
        "        assert obs.shape == inputShape\n",
        "        return obs.astype('uint8')  \n",
        "\n",
        "    def process_state_batch(self, batch):\n",
        "        batch = batch.astype('float32') / 255.\n",
        "        return batch\n",
        "\n",
        "    def process_reward(self, reward):\n",
        "        return np.clip(reward, -1., 1.)\n"
      ],
      "metadata": {
        "id": "SHmxf1QP0sSz"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# instantiate game env"
      ],
      "metadata": {
        "id": "0lu4sFVQ2o49"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "env = gym.make('SpaceInvadersDeterministic-v4')\n",
        "np.random.seed(123)\n",
        "env.seed(123)\n",
        "nb_actions = env.action_space.n\n",
        "print('number of actions',nb_actions)\n",
        "height ,width, channels = env.observation_space.shape\n",
        "print('types of actions:',env.unwrapped.get_action_meanings())\n",
        "print('height:{} width:{} channels:{}'.format(height,width, channels))"
      ],
      "metadata": {
        "id": "eYvEscnm2oQM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d267bf55-db31-4f97-e939-450529b56108"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of actions 6\n",
            "types of actions: ['NOOP', 'FIRE', 'RIGHT', 'LEFT', 'RIGHTFIRE', 'LEFTFIRE']\n",
            "height:210 width:160 channels:3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# build CNN model described by Mnih et al."
      ],
      "metadata": {
        "id": "p-WZ-LZ54zAX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "input_shape = (windowLength,) + inputShape\n",
        "print(input_shape)\n",
        "\n",
        "model1 = tf.keras.models.Sequential()\n",
        "model1.add(tf.keras.layers.Permute((2, 3, 1), input_shape=input_shape))\n",
        "model1.add(tf.keras.layers.Convolution2D(32, (8,8), strides=(4,4), activation='relu', input_shape=input_shape))\n",
        "model1.add(tf.keras.layers.Convolution2D(64, (4,4), strides=(2,2), activation='relu'))\n",
        "model1.add(tf.keras.layers.Convolution2D(64, (3,3), strides=(1,1), activation='relu'))\n",
        "model1.add(tf.keras.layers.Flatten())\n",
        "model1.add(tf.keras.layers.Dense(512, activation='relu'))\n",
        "model1.add(tf.keras.layers.Dense(env.action_space.n, activation=\"linear\"))\n",
        " \n",
        "    \n",
        "model1.summary()\n",
        "\n"
      ],
      "metadata": {
        "id": "vWIbUyzC41Mq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d28d754-d21b-4eb5-c489-0760ed91653b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4, 84, 84)\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " permute (Permute)           (None, 84, 84, 4)         0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 20, 20, 32)        8224      \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 9, 9, 64)          32832     \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 7, 7, 64)          36928     \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 3136)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 512)               1606144   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 6)                 3078      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,687,206\n",
            "Trainable params: 1,687,206\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# setting parameters"
      ],
      "metadata": {
        "id": "beEi961x_CH0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "memorylimit = 10000\n",
        "innerpolicy = EpsGreedyQPolicy()\n",
        "#innerpolicy = BoltzmannQPolicy()\n",
        "maxEps = 1.0\n",
        "minEps = 0.1\n",
        "testEps = 0.05\n",
        "annealSteps = 200000\n",
        "processor = AtariProcessor()\n",
        "warmup = 50000\n",
        "discount = 0.99\n",
        "target_model_update = 10000\n",
        "train_interval = 4\n",
        "delta_clip = 1.0\n",
        "lr = 0.00025\n",
        "trainingSteps = 1000000\n",
        "trainingLogInterval = 10000\n"
      ],
      "metadata": {
        "id": "9RhXzBSG_EDT"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# configure and compile the dqn agent\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Tlz8JpuF7U2c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "memory = SequentialMemory(limit=memorylimit, window_length=windowLength)\n",
        "policy = LinearAnnealedPolicy(innerpolicy, attr='eps', value_max=maxEps, value_min=minEps, value_test=testEps,nb_steps=annealSteps)\n",
        "#policy = BoltzmannQPolicy(tau=1.)\n",
        "dqn = DQNAgent(model=model1, nb_actions=nb_actions, policy=policy, memory=memory,\n",
        "               processor=processor,enable_double_dqn=False,enable_dueling_network=True, dueling_type='avg',  nb_steps_warmup=warmup, gamma=discount, target_model_update=target_model_update,\n",
        "               train_interval=train_interval, delta_clip=delta_clip)\n",
        "#adamOptimizer = adam_v2.Adam(learning_rate=0.00025)\n",
        "dqn.compile(tf.keras.optimizers.Adam(learning_rate=lr), metrics=[tf.keras.metrics.RootMeanSquaredError()])\n"
      ],
      "metadata": {
        "id": "Nb0iwXBY7XdL"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# train the agent"
      ],
      "metadata": {
        "id": "JMvmr_T78uNl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "env_name = 'SpaceInvadersDeterministic-v4'\n",
        "weights_filename = 'dqn_{}_weights.h5f'.format(env_name)\n",
        "checkpoint_weights_filename = 'dqn_' + env_name + '_weights_{step}.h5f'\n",
        "log_filename = 'dqn_{}_log.json'.format(env_name)\n",
        "callbacks = [ModelIntervalCheckpoint(checkpoint_weights_filename, interval=200000)]\n",
        "callbacks += [FileLogger(log_filename, interval=100)]\n",
        "trainLog = dqn.fit(env, callbacks=callbacks, nb_steps=trainingSteps, log_interval=trainingLogInterval)"
      ],
      "metadata": {
        "id": "q-d3syDK8ts5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# upload logs and models to drive"
      ],
      "metadata": {
        "id": "u8QAqGBZO3aG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gupload --to '1qvVYLfN8dghO2hSVGs9ruVDZzPV4rEux' *.h5f.*\n",
        "!gupload --to '1qvVYLfN8dghO2hSVGs9ruVDZzPV4rEux' dqn_SpaceInvadersDeterministic-v4_log.json"
      ],
      "metadata": {
        "id": "KocDkJTewRlr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}